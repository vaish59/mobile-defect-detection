{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (76.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vaishnavi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installing required libraries:\n",
    "# torch - Core PyTorch library for deep learning\n",
    "# torchvision - Supports image transformations, datasets, and pre-trained models\n",
    "# opencv-python - Used for image processing (reading, resizing, and drawing bounding boxes)\n",
    "# numpy - For numerical computations\n",
    "# matplotlib - For visualizing images and model outputs\n",
    "# scikit-learn - Useful for data preprocessing and evaluation metrics\n",
    "pip install torch torchvision opencv-python numpy matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Step 1: Define Dataset Path\n",
    "# ---------------------------------------------\n",
    "# The dataset contains images categorized into different defect types (Oil, Scratch, Stain).\n",
    "# Update the path as per your dataset location.\n",
    "DATASET_PATH = r\"C:\\Users\\Vaishnavi\\Desktop\\Istreet CV project\\dataset\"\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Step 2: Define Image Transformations\n",
    "# ---------------------------------------------\n",
    "# The transformations ensure that all images are resized to 224x224 pixels,\n",
    "# converted to tensors, and normalized for input to a deep learning model.\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize all images to 224x224\n",
    "    transforms.ToTensor(),          # Convert images to PyTorch tensors\n",
    "])\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Step 3: Create a Custom Dataset Class\n",
    "# ---------------------------------------------\n",
    "# This class loads the dataset, assigns labels, and applies transformations.\n",
    "class MobileDefectDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Path to the dataset directory containing defect folders.\n",
    "            transform (callable, optional): Transform to be applied on images.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = []  # List to store image file paths\n",
    "        self.labels = []       # List to store labels\n",
    "        self.classes = ['Oil', 'Scratch', 'Stain']  # List of defect categories\n",
    "\n",
    "        # Iterate through each defect category and gather image paths with corresponding labels\n",
    "        for idx, defect in enumerate(self.classes):\n",
    "            defect_folder = os.path.join(root_dir, defect)  # Path to category folder\n",
    "            for file in os.listdir(defect_folder):  # List all image files\n",
    "                self.image_files.append(os.path.join(defect_folder, file))  # Store image path\n",
    "                self.labels.append(idx)  # Assign numerical label (0: Oil, 1: Scratch, 2: Stain)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of images in the dataset.\"\"\"\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            idx (int): Index of the image to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            image (Tensor): Transformed image.\n",
    "            label (int): Corresponding defect category label.\n",
    "        \"\"\"\n",
    "        img_path = self.image_files[idx]  # Get image path\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # Open image and convert to RGB\n",
    "        label = self.labels[idx]  # Get corresponding label\n",
    "\n",
    "        # Apply transformations if specified\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label  # Return image tensor and label\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Step 4: Load the Dataset and Create DataLoader\n",
    "# ---------------------------------------------\n",
    "# The DataLoader is used to efficiently load images in batches for model training.\n",
    "dataset = MobileDefectDataset(DATASET_PATH, transform)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)  # Load images in batches of 32\n",
    "\n",
    "# Explanation:\n",
    "# - The dataset is loaded using MobileDefectDataset class.\n",
    "# - The DataLoader loads images in mini-batches of 32 and shuffles them for randomness.\n",
    "# - The output (image, label) pairs will be used for training a deep learning model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vaishnavi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Vaishnavi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load a pre-trained ResNet-18 model\n",
    "# ResNet-18 is a deep learning model commonly used for image classification.\n",
    "# We will fine-tune it for detecting mobile defects.\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Get the number of input features in the final fully connected (FC) layer\n",
    "num_features = model.fc.in_features\n",
    "\n",
    "# Replace the final layer to classify 3 defect types: Oil, Scratch, and Stain\n",
    "# The new layer has 3 output neurons corresponding to these classes.\n",
    "model.fc = nn.Linear(num_features, 3)\n",
    "\n",
    "# use the CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the selected device (CPU)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define the loss function\n",
    "# CrossEntropyLoss is used for multi-class classification problems.\n",
    "# It calculates the difference between predicted and actual class labels.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "# Adam optimizer is used to update model weights during training.\n",
    "# The learning rate (lr) is set to 0.001, which controls the step size during updates.\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.1735, Accuracy: 0.9358\n",
      "Epoch [2/10], Loss: 0.0226, Accuracy: 0.9933\n",
      "Epoch [3/10], Loss: 0.0058, Accuracy: 0.9983\n",
      "Epoch [4/10], Loss: 0.0028, Accuracy: 1.0000\n",
      "Epoch [5/10], Loss: 0.0064, Accuracy: 0.9983\n",
      "Epoch [6/10], Loss: 0.0095, Accuracy: 0.9967\n",
      "Epoch [7/10], Loss: 0.0065, Accuracy: 0.9983\n",
      "Epoch [8/10], Loss: 0.1340, Accuracy: 0.9633\n",
      "Epoch [9/10], Loss: 0.0263, Accuracy: 0.9925\n",
      "Epoch [10/10], Loss: 0.0688, Accuracy: 0.9817\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {correct/total:.4f}\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9833\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, test_loader):\n",
    "    \"\"\"\n",
    "    Function to evaluate the trained model on the test dataset.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained deep learning model.\n",
    "        test_loader (DataLoader): DataLoader containing test dataset batches.\n",
    "\n",
    "    Returns:\n",
    "        None (Prints the test accuracy)\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode (disables dropout & batch norm updates)\n",
    "    correct = 0  # Counter for correctly classified samples\n",
    "    total = 0  # Total number of samples\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for faster inference\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Move data to GPU (if available)\n",
    "            outputs = model(images)  # Forward pass: get model predictions\n",
    "            _, predicted = torch.max(outputs, 1)  # Get class index with highest probability\n",
    "            correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "            total += labels.size(0)  # Update total samples count\n",
    "\n",
    "    # Print the model's accuracy on the test dataset\n",
    "    print(f\"Test Accuracy: {correct / total:.4f}\")\n",
    "\n",
    "# Load test dataset\n",
    "test_dataset = MobileDefectDataset(DATASET_PATH, transform)\n",
    "\n",
    "# Create DataLoader for the test dataset (batch size of 32, no shuffling)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Evaluate model performance on test data\n",
    "test_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"mobile_defect_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Defect: Scratch\n"
     ]
    }
   ],
   "source": [
    "def predict_image(image_path, model, transform):\n",
    "    \"\"\"\n",
    "    Function to predict the defect type in an image using the trained model.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "        model (torch.nn.Module): The trained deep learning model.\n",
    "        transform (torchvision.transforms.Compose): Transformations to apply to the input image.\n",
    "\n",
    "    Returns:\n",
    "        str: The predicted defect type (Oil, Scratch, or Stain).\n",
    "    \"\"\"\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # Open image and convert to RGB\n",
    "    image = transform(image).unsqueeze(0).to(device)  # Apply transformations and add batch dimension\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient calculation for inference\n",
    "        output = model(image)  # Get model predictions\n",
    "        _, predicted = torch.max(output, 1)  # Get the class index with highest probability\n",
    "\n",
    "    # Define class labels\n",
    "    classes = ['Oil', 'Scratch', 'Stain']\n",
    "\n",
    "    # Return the predicted class name\n",
    "    return classes[predicted.item()]\n",
    "\n",
    "# Test an image for defect prediction\n",
    "image_path = r\"C:\\Users\\Vaishnavi\\Desktop\\Istreet CV project\\dataset\\scratch\\Scr_0001.jpg\"\n",
    "prediction = predict_image(image_path, model, transform)\n",
    "print(\"Predicted Defect:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98       400\n",
      "           1       1.00      0.96      0.98       400\n",
      "           2       1.00      0.99      0.99       400\n",
      "\n",
      "    accuracy                           0.98      1200\n",
      "   macro avg       0.98      0.98      0.98      1200\n",
      "weighted avg       0.98      0.98      0.98      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the subset size to limit the test set for evaluation\n",
    "subset_size = 100  # Reduce test set size to speed up evaluation\n",
    "\n",
    "# Lists to store true and predicted labels\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation for inference\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        if i >= subset_size:  # Stop after processing subset_size batches\n",
    "            break\n",
    "\n",
    "        # Move images and labels to CPU for evaluation\n",
    "        images, labels = images.to(\"cpu\"), labels.to(\"cpu\")\n",
    "\n",
    "        # Get model predictions\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the class with highest probability\n",
    "\n",
    "        # Store true and predicted labels for classification report\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(predicted.numpy())\n",
    "\n",
    "# Print classification report (precision, recall, F1-score) for model evaluation\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98       400\n",
      "           1       1.00      0.96      0.98       400\n",
      "           2       1.00      0.99      0.99       400\n",
      "\n",
      "    accuracy                           0.98      1200\n",
      "   macro avg       0.98      0.98      0.98      1200\n",
      "weighted avg       0.98      0.98      0.98      1200\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print classification report\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Compute Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Define class labels\n",
    "classes = [\"Oil\", \"Scratch\", \"Stain\"]  # Update if needed\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
